{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add the parent directory to the Python path to import WeatherData class\n",
    "CURRENT_DIR = os.path.normpath(os.path.dirname(os.getcwd()))\n",
    "# parent_dir = os.path.normpath(os.path.dirname(CURRENT_DIR))\n",
    "sys.path.append(CURRENT_DIR)\n",
    "\n",
    "from classes.weather_data_transform import WeatherDataTransform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data_dir = \"../../data/weather_data\"\n",
    "\n",
    "sorted_filenames = sorted(\n",
    "    [file.split(\".\")[0] for file in os.listdir(os.path.normpath(weather_data_dir)) if \".parquet\" in file and \"transformed\" not in file]\n",
    ")\n",
    "sorted_file_dirs = [os.path.join(\n",
    "    os.path.normpath(weather_data_dir), file\n",
    ") for file in sorted_filenames]\n",
    "\n",
    "for file in sorted_filenames:\n",
    "    # Define file paths to load and save\n",
    "    file_path = os.path.join(os.path.normpath(weather_data_dir), f\"{file}.parquet\")\n",
    "    save_path = os.path.join(os.path.normpath(weather_data_dir), f\"{file}_transformed.parquet\")\n",
    "    # Transform data\n",
    "    df = WeatherDataTransform.transform_individual_locations(\n",
    "        file_path=file_path\n",
    "    )\n",
    "    # Save transformed data\n",
    "    df.to_parquet(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>minutes_after_midnight</th>\n",
       "      <th>temperature</th>\n",
       "      <th>weather</th>\n",
       "      <th>hour_number</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-01-26 19:00:00</th>\n",
       "      <td>2024-01-26</td>\n",
       "      <td>1140</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-26 20:00:00</th>\n",
       "      <td>2024-01-26</td>\n",
       "      <td>1200</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-26 21:00:00</th>\n",
       "      <td>2024-01-26</td>\n",
       "      <td>1260</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>21:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-26 22:00:00</th>\n",
       "      <td>2024-01-26</td>\n",
       "      <td>1320</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-26 23:00:00</th>\n",
       "      <td>2024-01-26</td>\n",
       "      <td>1380</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>23:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            day  minutes_after_midnight  temperature  weather  \\\n",
       "date                                                                            \n",
       "2024-01-26 19:00:00  2024-01-26                    1140          7.0        0   \n",
       "2024-01-26 20:00:00  2024-01-26                    1200          6.7        0   \n",
       "2024-01-26 21:00:00  2024-01-26                    1260          6.9        2   \n",
       "2024-01-26 22:00:00  2024-01-26                    1320          8.0        4   \n",
       "2024-01-26 23:00:00  2024-01-26                    1380          7.3        4   \n",
       "\n",
       "                     hour_number      hour  \n",
       "date                                        \n",
       "2024-01-26 19:00:00           19  19:00:00  \n",
       "2024-01-26 20:00:00           20  20:00:00  \n",
       "2024-01-26 21:00:00           21  21:00:00  \n",
       "2024-01-26 22:00:00           22  22:00:00  \n",
       "2024-01-26 23:00:00           23  23:00:00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transformed = WeatherDataTransform.transform_individual_locations(\n",
    "    \"../../data/weather_data/3316_crosby_weather_data.parquet\"\n",
    ")\n",
    "df_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_transformed.loc[(df_transformed.index > \"02-10-2024\") & (df_transformed.index < \"02-17-2024\")][\"temperature\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_dict_original = {\n",
    "    0: \"Clear night\",\n",
    "    1: \"Sunny day\",\n",
    "    2: \"Partly cloudy (night)\",\n",
    "    3: \"Partly cloudy (day)\",\n",
    "    4: \"Not used\",\n",
    "    5: \"Mist\",\n",
    "    6: \"Fog\",\n",
    "    7: \"Cloudy\",\n",
    "    8: \"Overcast\",\n",
    "    9: \"Light rain shower (night)\",\n",
    "    10: \"Light rain shower (day)\",\n",
    "    11: \"Drizzle\",\n",
    "    12: \"Light rain\",\n",
    "    13: \"Heavy rain shower (night)\",\n",
    "    14: \"Heavy rain shower (day)\",\n",
    "    15: \"Heavy rain\",\n",
    "    16: \"Sleet shower (night)\",\n",
    "    17: \"Sleet shower (day)\",\n",
    "    18: \"Sleet\",\n",
    "    19: \"Hail shower (night)\",\n",
    "    20: \"Hail shower (day)\",\n",
    "    21: \"Hail\",\n",
    "    22: \"Light snow shower (night)\",\n",
    "    23: \"Light snow shower (day)\",\n",
    "    24: \"Light snow\",\n",
    "    25: \"Heavy snow shower (night)\",\n",
    "    26: \"Heavy snow shower (day)\",\n",
    "    27: \"Heavy snow\",\n",
    "    28: \"Thunder shower (night)\",\n",
    "    29: \"Thunder shower (day)\",\n",
    "    30: \"Thunder?\"\n",
    "}\n",
    "\n",
    "weather_dict_merged = {\n",
    "    0: \"Clear night\",\n",
    "    1: \"Sunny day\",\n",
    "    2: \"Partly cloudy\",\n",
    "    3: \"Not used\",\n",
    "    4: \"Mist\",\n",
    "    5: \"Fog\",\n",
    "    6: \"Cloudy\",\n",
    "    7: \"Overcast\",\n",
    "    8: \"Light rain\",\n",
    "    9: \"Drizzle\",\n",
    "    10: \"Heavy rain\",\n",
    "    11: \"Sleet\",\n",
    "    12: \"Hail\",\n",
    "    13: \"Light snow\",\n",
    "    14: \"Heavy snow\",\n",
    "    15: \"Thunder\"\n",
    "}\n",
    "\n",
    "weather_dict_mapping = {\n",
    "    0: 0,\n",
    "    1: 1,\n",
    "    2: 2,\n",
    "    3: 2,\n",
    "    4: 3,\n",
    "    5: 4,\n",
    "    6: 5,\n",
    "    7: 6,\n",
    "    8: 7,\n",
    "    9: 8,\n",
    "    10: 8,\n",
    "    11: 9,\n",
    "    12: 8,\n",
    "    13: 10,\n",
    "    14: 10,\n",
    "    15: 10,\n",
    "    16: 11,\n",
    "    17: 11,\n",
    "    18: 11,\n",
    "    19: 12,\n",
    "    20: 12,\n",
    "    21: 12,\n",
    "    22: 13,\n",
    "    23: 13,\n",
    "    24: 13,\n",
    "    25: 14,\n",
    "    26: 14,\n",
    "    27: 14,\n",
    "    28: 15,\n",
    "    29: 15,\n",
    "    30: 15\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data_dir = \"../../data/weather_data\"\n",
    "\n",
    "sorted_filenames = sorted(\n",
    "    [file for file in os.listdir(os.path.normpath(weather_data_dir)) if \".parquet\" in file and \"transformed\" in file]\n",
    ")\n",
    "sorted_file_dirs = [os.path.join(\n",
    "    os.path.normpath(weather_data_dir), file\n",
    ") for file in sorted_filenames]\n",
    "\n",
    "df_dict = {\n",
    "    \"crossby_df\": pd.read_parquet(sorted_file_dirs[0]),\n",
    "    \"bingley_df\": pd.read_parquet(sorted_file_dirs[1]),\n",
    "    \"rostherne_df\": pd.read_parquet(sorted_file_dirs[2]),\n",
    "    \"watnall_df\": pd.read_parquet(sorted_file_dirs[3]),\n",
    "    \"coleshill_df\": pd.read_parquet(sorted_file_dirs[4]),\n",
    "    \"heathrow_df\": pd.read_parquet(sorted_file_dirs[5]),\n",
    "    \"thorney_df\": pd.read_parquet(sorted_file_dirs[6])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scaled_temperature(\n",
    "        df_dict: dict[pd.DataFrame],\n",
    "        population_scaling: dict[float]\n",
    ") -> pd.Series:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        * df_dict (dict[pd.DataFrame]): _description_\n",
    "        * population_scaling (dict[float]): _description_\n",
    "\n",
    "    Returns:\n",
    "        * pd.Series: _description_\n",
    "    \"\"\"\n",
    "    scaled_temperature_all = 0\n",
    "    # Iterate over each key-value pair in df_dict\n",
    "    for df_name, df in df_dict.items():\n",
    "        # Multiply the \"temperature\" column by the scaling factor for the current DataFrame\n",
    "        scaled_temperature = df['temperature'] * population_scaling[df_name]\n",
    "        print(scaled_temperature)\n",
    "        # Add the scaled temperature to the total sum\n",
    "        scaled_temperature_all += scaled_temperature\n",
    "\n",
    "    return scaled_temperature_all\n",
    "\n",
    "def get_max_weather(\n",
    "        weather_vals: pd.Series, population_scaling: dict[float]\n",
    ") -> list:\n",
    "    weather_aggregates = []\n",
    "    unique_weathers = set(weather_vals)\n",
    "    for weather in unique_weathers:\n",
    "        weather_locations = weather_vals[weather_vals == weather].index.to_list()\n",
    "        aggregate = sum([population_scaling[location] for location in weather_locations if location in population_scaling])\n",
    "        weather_aggregates.append(aggregate)\n",
    "        # print(f\"Sum of weights for weather {weather} is {aggregate}\")\n",
    "    index_max = weather_aggregates.index(max(weather_aggregates))\n",
    "    # print(f\"Weather to keep is: {list(unique_weathers)[index_max]}\")\n",
    "\n",
    "    return list(unique_weathers)[index_max]\n",
    "\n",
    "def generate_all_information_df(df_dict: dict[pd.DataFrame]) -> pd.DataFrame:\n",
    "    # Create a dict containing the population in millions\n",
    "    # of the closest big city\n",
    "    area_population = {\n",
    "        \"crossby_df\": 0.9, # Liverpool\n",
    "        \"bingley_df\": 0.8, # Leeds\n",
    "        \"rostherne_df\": 2.9, # Manchester\n",
    "        \"watnall_df\": 0.8, # Nottingham\n",
    "        \"coleshill_df\": 4.3, # Birmingham\n",
    "        \"heathrow_df\": 9.5, # London\n",
    "        \"thorney_df\": 1.5 # Southampton and Portsmouth\n",
    "    }\n",
    "    total_population = sum([value for value in area_population.values()])\n",
    "    # Calculate population ration for each of the locations\n",
    "    population_scaling = {key:value/total_population for (key, value) in area_population.items()}\n",
    "    \n",
    "    # Find the common indices\n",
    "    indices_list = [df.index for df in df_dict.values()]\n",
    "    common_indices = sorted(list(set(indices_list[0]).intersection(*indices_list[1:])))\n",
    "    # Keep the common indices for each of the dataframes\n",
    "    df_dict = {df_name:df.loc[common_indices] for (df_name,df) in df_dict.items()}\n",
    "\n",
    "    # Extract scaled temperature across all the locations\n",
    "    scaled_temperature = calculate_scaled_temperature(\n",
    "        df_dict, population_scaling\n",
    "    )\n",
    "\n",
    "    # Initialize an empty DataFrame to store the \"weather\" column from each DataFrame\n",
    "    weather_df = pd.DataFrame()\n",
    "    # Iterate over each key-value pair in df_dict\n",
    "    for df_name, df in df_dict.items():\n",
    "        # Concatenate the \"weather\" column from the current DataFrame to weather_df\n",
    "        weather_df[df_name] = df['weather']\n",
    "    # Create a column containing the weather value with the highest weight\n",
    "    max_weather = weather_df.apply(\n",
    "        get_max_weather, axis=1, population_scaling=population_scaling\n",
    "    )\n",
    "\n",
    "    # Create a dataframe that combines the scaled temperature\n",
    "    # and the highest weighted weather value\n",
    "    df_combined = pd.DataFrame(\n",
    "        {\n",
    "            \"temperature\": scaled_temperature,\n",
    "            \"weather\": max_weather\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_list = [df.index for df in df_dict.values()]\n",
    "\n",
    "common_indices = sorted(list(set(indices_list[0]).intersection(*indices_list[1:])))\n",
    "\n",
    "df_dict = {df_name:df.loc[common_indices] for (df_name,df) in df_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'crossby_df': 0.04347826086956522,\n",
       " 'bingley_df': 0.03864734299516909,\n",
       " 'rostherne_df': 0.14009661835748793,\n",
       " 'watnall_df': 0.03864734299516909,\n",
       " 'coleshill_df': 0.20772946859903382,\n",
       " 'heathrow_df': 0.4589371980676329,\n",
       " 'thorney_df': 0.07246376811594203}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area_population = {\n",
    "    \"crossby_df\": 0.9,\n",
    "    \"bingley_df\": 0.8,\n",
    "    \"rostherne_df\": 2.9,\n",
    "    \"watnall_df\": 0.8,\n",
    "    \"coleshill_df\": 4.3,\n",
    "    \"heathrow_df\": 9.5,\n",
    "    \"thorney_df\": 1.5\n",
    "}\n",
    "total_population = sum([value for value in area_population.values()])\n",
    "population_scaling = {key:value/total_population for (key, value) in area_population.items()}\n",
    "population_scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2024-01-26 19:00:00     5.796135\n",
       "2024-01-26 20:00:00     5.328502\n",
       "2024-01-26 21:00:00     4.328019\n",
       "2024-01-26 22:00:00     4.849758\n",
       "2024-01-26 23:00:00     3.576329\n",
       "                         ...    \n",
       "2024-04-09 17:00:00    10.667150\n",
       "2024-04-09 18:00:00    10.294686\n",
       "2024-04-09 19:00:00     9.450725\n",
       "2024-04-09 20:00:00     9.010628\n",
       "2024-04-09 21:00:00     7.912077\n",
       "Name: temperature, Length: 1725, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the total sum\n",
    "# total_sum = pd.Series()\n",
    "scaled_temperature_all = 0\n",
    "weather_list = []\n",
    "# Iterate over each key-value pair in df_dict\n",
    "for df_name, df in df_dict.items():\n",
    "    # Multiply the \"temperature\" column by the scaling factor for the current DataFrame\n",
    "    scaled_temperature = df['temperature'] * population_scaling[df_name]\n",
    "    # print(scaled_temperature)\n",
    "    # Add the scaled temperature to the total sum\n",
    "    scaled_temperature_all += scaled_temperature\n",
    "\n",
    "scaled_temperature_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_max_weather_extra_params(weather_vals: pd.Series, population_scaling: dict):\n",
    "#     weather_aggregates = []\n",
    "#     unique_weathers = set(weather_vals)\n",
    "#     for weather in unique_weathers:\n",
    "#         weather_locations = weather_vals[weather_vals == weather].index.to_list()\n",
    "#         aggregate = sum([population_scaling[location] for location in weather_locations if location in population_scaling])\n",
    "#         weather_aggregates.append(aggregate)\n",
    "#         # print(f\"Sum of weights for weather {weather} is {aggregate}\")\n",
    "#     index_max = weather_aggregates.index(max(weather_aggregates))\n",
    "#     # print(f\"Weather to keep is: {list(unique_weathers)[index_max]}\")\n",
    "\n",
    "#     return list(unique_weathers)[index_max]\n",
    "\n",
    "# def get_max_weather(weather_vals: pd.Series):\n",
    "#     weather_aggregates = []\n",
    "#     unique_weathers = set(weather_vals)\n",
    "#     for weather in unique_weathers:\n",
    "#         weather_locations = weather_vals[weather_vals == weather].index.to_list()\n",
    "#         aggregate = sum([population_scaling[location] for location in weather_locations if location in population_scaling])\n",
    "#         weather_aggregates.append(aggregate)\n",
    "#         # print(f\"Sum of weights for weather {weather} is {aggregate}\")\n",
    "#     index_max = weather_aggregates.index(max(weather_aggregates))\n",
    "#     # print(f\"Weather to keep is: {list(unique_weathers)[index_max]}\")\n",
    "\n",
    "#     return list(unique_weathers)[index_max]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crossby_df</th>\n",
       "      <th>bingley_df</th>\n",
       "      <th>rostherne_df</th>\n",
       "      <th>watnall_df</th>\n",
       "      <th>coleshill_df</th>\n",
       "      <th>heathrow_df</th>\n",
       "      <th>thorney_df</th>\n",
       "      <th>max_weather_extra_params</th>\n",
       "      <th>max_weather</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-01-26 19:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-26 20:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-26 21:00:00</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-26 22:00:00</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-26 23:00:00</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     crossby_df  bingley_df  rostherne_df  watnall_df  \\\n",
       "date                                                                    \n",
       "2024-01-26 19:00:00           0           0             0           0   \n",
       "2024-01-26 20:00:00           0           2             0           0   \n",
       "2024-01-26 21:00:00           2           0             0           0   \n",
       "2024-01-26 22:00:00           4           6             0           0   \n",
       "2024-01-26 23:00:00           4           0             0           2   \n",
       "\n",
       "                     coleshill_df  heathrow_df  thorney_df  \\\n",
       "date                                                         \n",
       "2024-01-26 19:00:00             0            0           0   \n",
       "2024-01-26 20:00:00             6            0           0   \n",
       "2024-01-26 21:00:00             0            0           0   \n",
       "2024-01-26 22:00:00             7            0           0   \n",
       "2024-01-26 23:00:00             7            0           4   \n",
       "\n",
       "                     max_weather_extra_params  max_weather  \n",
       "date                                                        \n",
       "2024-01-26 19:00:00                         0            0  \n",
       "2024-01-26 20:00:00                         0            0  \n",
       "2024-01-26 21:00:00                         0            0  \n",
       "2024-01-26 22:00:00                         0            0  \n",
       "2024-01-26 23:00:00                         0            0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize an empty DataFrame to store the \"weather\" column from each DataFrame\n",
    "weather_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over each key-value pair in df_dict\n",
    "for df_name, df in df_dict.items():\n",
    "    # Concatenate the \"weather\" column from the current DataFrame to weather_df\n",
    "    weather_df[df_name] = df['weather']\n",
    "\n",
    "weather_df[\"max_weather\"] = weather_df.apply(get_max_weather, axis=1, population_scaling=population_scaling)\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df[weather_df[\"heathrow_df\"] != weather_df[\"max_weather\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.DataFrame(\n",
    "    {\n",
    "        \"temperature\": scaled_temperature_all,\n",
    "        \"weather\": weather_df[\"max_weather\"]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Things to do\n",
    "\n",
    "* Decide which columns are the important columns. Think about what information is available for the predictions\n",
    "* Remove outliers for the chosen columns and for all datasets\n",
    "* Once cleaned, it's time for feature engineering:\n",
    "    * Let's use an weighed-average temperature based on population of the area, e.g. if London has 10% of the population, then london_temp*0.1\n",
    "    * Try to use an \"average\" climate condition: e.g. cloudy, sunny... It could be encoded as a number, but it wouldn't make much sense in real life\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
